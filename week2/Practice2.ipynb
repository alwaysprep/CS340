{
    "cells": [
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The code was removed by DSX for sharing.", 
            "execution_count": 4
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "# Calculating The Mean Of Movie Ratings"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "In this notebook we are going to calculate the mean of the movie ratings by using spark.\n\nFirst, you should install the <a href=\"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\">data</a> and unzip it.\n\nFor the purpose of this notebook, we are going to use only the ratings.csv file.\n\nNext we need to remove the first line of ratings.csv and upload it. \n\nAfter that click insert to code > insert spark RDD."
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "data = sc.textFile(\"\"\"Paste the path from the autogenerated code\"\"\")", 
            "execution_count": 5
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "[u'1,31,2.5,1260759144',\n u'1,1029,3.0,1260759179',\n u'1,1061,3.0,1260759182',\n u'1,1129,2.0,1260759185',\n u'1,1172,4.0,1260759205']"
                    }, 
                    "metadata": {}, 
                    "execution_count": 6
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# In order to see the structure of the data\ndata.take(5)\n# we take 5 of them", 
            "execution_count": 6
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "The only thing of our interes is ratings, and it is in the third column.\nIf we know hot parse a row, we can appy to all rows by using spark's map method."
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "2.5"
                    }, 
                    "metadata": {}, 
                    "execution_count": 7
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# Lets play with the first row\na_row = u'1,31,2.5,1260759144'\nfloat(a_row.split(\",\")[2])\n# here we split it take the third column and conver it to float in one line.", 
            "execution_count": 7
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# however in order to make our spark code more readable we can seperete those tasks.\nratings = data.map(lambda a_row: a_row.split(\",\"))\\\n    .map(lambda lis: lis[2])\\\n    .map(float)\n    \ntotal_rating = ratings.reduce(lambda x,y : x+y)", 
            "execution_count": 8
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "num_or_rating = ratings.count()", 
            "execution_count": 9
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "mean = total_rating/num_or_rating", 
            "execution_count": 10
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "3.54360825567\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "print mean", 
            "execution_count": 11
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "execution_count": null
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "version": "2.7.11", 
            "file_extension": ".py", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "nbconvert_exporter": "python", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat_minor": 0
}